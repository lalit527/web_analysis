{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "\n",
    "import numba\n",
    "from typing import Tuple, Dict, Collection, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_holidays(tagged, start, end):\n",
    "    def read_df(lang):\n",
    "        result = pd.read_pickle('data/holidays/%s.pkl' % lang)\n",
    "        return result[~result.dw].resample('D').size().rename(lang)\n",
    "\n",
    "    holidays = pd.DataFrame([read_df(lang) for lang in ['de', 'en', 'es', 'fr', 'ja', 'ru', 'zh']])\n",
    "    holidays = holidays.loc[:, start:end].fillna(0)\n",
    "    result =tagged[['country']].join(holidays, on='country').drop('country', axis=1).fillna(0).astype(np.int8)\n",
    "    result.columns = pd.DatetimeIndex(result.columns.values)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_autocorr(series, lag):\n",
    "    s1 = series[lag:]\n",
    "    s2 = series[:-lag]\n",
    "    ms1 = np.mean(s1)\n",
    "    ms2 = np.mean(s2)\n",
    "    ds1 = s1 - ms1\n",
    "    ds2 = s2 - ms2\n",
    "    divider = np.sqrt(np.sum(ds1 * ds1)) * np.sqrt(np.sum(ds2 * ds2))\n",
    "    return np.sum(ds1 * ds2) / divider if divider != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_autocorr(data, lag, starts, ends, threshold, backoffset=0):\n",
    "    n_series = data.shape[0]\n",
    "    n_days = data.shape[1]\n",
    "    max_end = n_days - backoffset\n",
    "    corr = np.empty(n_series, dtype=np.float64)\n",
    "    support = np.empty(n_series, dtype=np.float64)\n",
    "    for i in range(n_series):\n",
    "        series = data[i]\n",
    "        end = min(ends[i], max_end)\n",
    "        real_len = end - starts[i]\n",
    "        support[i] = real_len/lag\n",
    "        if support[i] > threshold:\n",
    "            series = series[starts[i]:end]\n",
    "            c_365 = single_autocorr(series, lag)\n",
    "            c_364 = single_autocorr(series, lag-1)\n",
    "            c_366 = single_autocorr(series, lag+1)\n",
    "            corr[i] = 0.5 * c_365 + 0.25 * c_364 + 0.25 * c_366\n",
    "        else:\n",
    "            corr[i] = np.NaN\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_end(data: np.ndarray):\n",
    "    n_pages = data.shape[0]\n",
    "    n_days = data.shape[1]\n",
    "    start_idx = np.full(n_pages, -1, dtype=np.int32)\n",
    "    end_idx = np.full(n_pages, -1, dtype=np.int32)\n",
    "    for page in range(n_pages):\n",
    "        for day in range(n_days):\n",
    "            if not np.isnan(data[page, day]) and data[page, day] > 0:\n",
    "                start_idx[page] = day\n",
    "                break\n",
    "        for day in range(n_days - 1, -1, -1):\n",
    "            if not np.isnan(data[page, day]) and data[page, day] > 0:\n",
    "                end_idx[page] = day\n",
    "                break\n",
    "    return start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(start, end, valid_threshold):\n",
    "    df = read_x(start, end)\n",
    "    starts, ends = find_start_end(df.values)\n",
    "    page_mask = (ends - starts) / df.shape[1] < valid_threshold\n",
    "    print(\"Masked %d pages from %d\" % (page_mask.sum(), len(df)))\n",
    "    inv_mask = ~page_mask\n",
    "    df = df[inv_mask]\n",
    "    nans = pd.isnull(df)\n",
    "    return np.log1p(df.fillna(0)), nans, starts[inv_mask], ends[inv_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_indexes(begin, end):\n",
    "    dr = pd.date_range(begin, end)\n",
    "    base_index = pd.Series(np.arange(0, len(dr)), index=dr)\n",
    "    def lag(offset):\n",
    "        dates = dr - offset\n",
    "        return pd.Series(data=base_index.loc[dates].fillna(-1).astype(np.int16).values, index=dr)\n",
    "    return [lag(pd.DateOffset(months=m)) for m in (3, 6, 9, 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_page_features(pages: np.ndarray):\n",
    "    tagged = extractor.extract(pages).set_index('page')\n",
    "    features: pd.DataFrame = tagged.drop(['term', 'marker'], axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniq_page_map(pages):\n",
    "    import re\n",
    "    result = np.full([len(pages), 4], -1, dtype=np.int32)\n",
    "    pat = re.compile('(.+(?:(?:wikipedia\\.org)|(?:commons\\.wikimedia\\.org)|(?:www\\.mediawiki\\.org)))_([a-z_-]+?)')\n",
    "    prev_page = None\n",
    "    num_page = -1\n",
    "    agents = {'all-access_spider': 0, 'desktop_all-agents': 1, 'mobile-web_all-agents': 2, 'all-access_all-agents': 3}\n",
    "    for i, entity in enumerate(pages):\n",
    "        match = pat.fullmatch(entity)\n",
    "        assert match\n",
    "        page = match.group(1)\n",
    "        agent = match.group(2)\n",
    "        if page != prev_page:\n",
    "            prev_page = page\n",
    "            num_page += 1\n",
    "        result[num_page, agents[agent]] = i\n",
    "    return result[:num_page+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_page_features(df):\n",
    "    def encode(column):\n",
    "        one_hot = pd.get_dummies(df[column], drop_first=False)\n",
    "        return (one_hot - one_hot.mean()) / one_hot.std()\n",
    "\n",
    "    return {str(column): encode(column) for column in df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(values: np.ndarray):\n",
    "    return (values - values.mean()) / np.std(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
